
networks:
  web:
  internal:

services:

  cng-hello-backend:
    image: cng-hello-backend:latest
    ports:
      - "4200:4200"
    environment:
      PORT: "4200"
      POSTGRES_HOST: "postgres"
      POSTGRES_PORT: "5432"
      POSTGRES_USER: "user"
      POSTGRES_PASSWORD: "password"
      POSTGRES_DB: "cngdb"
      LOG_LEVEL: "DEBUG"
      OTEL_COLLECTOR_ENDPOINT: "otel-collector:4317"
    networks:
      - web
      - internal
    depends_on:
      - postgres
      - otel-collector

  postgres:
    image: postgres:14-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: cngdb
    networks:
      - internal

# MONITORING
  otel-collector:
    image: otel/opentelemetry-collector:0.79.0
    command: [ "--config=/etc/otel-collector.yaml" ]
    volumes:
      - ./otel-collector.yaml:/etc/otel-collector.yaml
    ports:
        - "4317:4317" # OTLP over gRPC receiver
        - "8888:8888" # Prometheus metrics exposed by the collector
        - "8889:8889" # Prometheus exporter metrics
    networks:
      - internal
    depends_on:
      - prometheus
      - tempo

  prometheus:
    image: prom/prometheus:v2.44.0
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      [
        '--config.file=/etc/prometheus/prometheus.yml',
        '--enable-feature=remote-write-receiver',
      ]
    networks:
      - web
      - internal

  grafana:
    image: grafana/grafana:9.5.3
    ports:
      - 3000:3000
    environment:
      - GF_ALERTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_ANALYTICS_CHECK_FOR_PLUGIN_UPDATES=false
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    networks:
      - web
      - internal

  tempo:
    image: grafana/tempo:2.1.1
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml
     # - ./tempo-data:/tmp/tempo
    ports:
      - "3200"   # tempo
      - "4317"  # otlp grpc
    depends_on:
      - minio
    networks:
      - internal 

  loki:
    image: grafana/loki:2.8.2
    command: "-config.file=/etc/loki/config.yaml"
    ports:
      - 3100:3100
      - 7946
      - 9095
    volumes:
      - ./loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - internal

  promtail:
    image: grafana/promtail:2.8.2
    volumes:
      - ./promtail-config.yaml:/etc/promtail/config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yaml
    networks:
      - internal

  minio:
    image: minio/minio
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        mkdir -p /data/tempo-data && \
        minio server --console-address ":9001" /data
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=supersecret
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_UPDATE=off
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - minio-data:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    networks:
      - internal

volumes:
  grafana-data:
  minio-data: